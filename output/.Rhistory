})
registerDoSEQ() #register cores to compute sequentially
bfi_tbl_long <-  bfi_tbl_group %>% slice(1:1e5)  #2.5 mil (2500k)
bfi_ls <- split(
bfi_tbl_long[, !names(bfi_tbl_long) == "item" ],  #split into list but remove the item variable
bfi_tbl_long$item #split on item variable
)
system.time({
rstatix::cohens_d(bfi_tbl_long, score ~ gender)
})
registerDoParallel(detectCores() - 1) #register the cluster to run in parallel
system.time({
d_gender <-
foreach(i=1:25) %dopar% {
rstatix::cohens_d(bfi_ls[[i]], score ~ gender)
}
})
registerDoSEQ() #register cores to compute sequentially
bfi_tbl_long <-  bfi_tbl_group %>% slice(1:1e6)  #2.5 mil (2500k)
rbindlist(d_gender)
benchmark(
dplyr::bind_rows(d_gender),
data.table::rbindlist(d_gender),
replications = 10,
columns = c("test","elapsed"),
order = "elapsed"
)
rbindlist(d_gender)
benchmark(
dplyr::bind_rows(d_gender),
data.table::rbindlist(d_gender) %>% as_tibble,
replications = 10,
columns = c("test","elapsed"),
order = "elapsed"
)
benchmark(
dplyr::bind_rows(d_gender),
data.table::rbindlist(d_gender) %>% as_tibble,
replications = 10,
columns = c("test","elapsed"),
order = "elapsed"
)
rbindlist(d_gender) %>% as_tibble()
tbl$letter
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #comment out when knitting the notebook
# let's start coding!
install.packages("pacman")
# let's start coding!
install.packages("pacman")
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #comment out when knitting the notebook
pacman::p_load(
tidyverse, psych, DT, doParallel, data.table, rbenchmark, benchmarkme, microbenchmark, vroom, disk.frame, knitr
)
opts_chunk$set(echo=T, cache=F, prompt=F, tidy=T, comment=NA, message=F, warning=F)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #comment out when knitting the notebook
pacman::p_load(
tidyverse, psych, DT, doParallel, data.table, rbenchmark, benchmarkme, microbenchmark, vroom, disk.frame, knitr
)
opts_chunk$set(echo=T, cache=F, prompt=F, tidy=T, comment=NA, message=F, warning=F)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #comment out when knitting the notebook
pacman::p_load(
tidyverse, psych, DT, doParallel, data.table, rbenchmark, benchmarkme, microbenchmark, vroom, disk.frame, knitr
)
opts_chunk$set(echo=T, cache=F, prompt=F, tidy=T, comment=NA, message=F, warning=F)
# get major and minor version and paste together
paste0(version$major, ".", version$minor)
# benchmarkme  should already be loaded in your global environment
paste("RAM:", disk.frame::df_ram_size(), "GB") #how much RAM are you working with?
paste("CPUs:", benchmarkme::get_cpu()[3]) #how many logical processors do you have?
benchmarkme::get_cpu()
benchmarkme::get_cpu()[3]
paste("CPUs:", benchmarkme::get_cpu()[3]) #how many logical processors do you have?
write_read_bench <- benchmark_io( size = 5 ) #read and write benchmark
plot(write_read_bench) #plot results
upload_results(write_read_bench) #upload results for benchmark tracking
1e5
n <- 1e5
col <- 100
get_random_df(n_elements = n, ncol = col)
get_random_df <-
function(n_elements, ncol, min = 0, max = 1, seed = 42) {
seed <- set.seed(seed)
n <- n_elements #number of elements in a vector
x <- runif(n, min = min, max = max) #random vector of real numbers
x <- matrix(x, ncol=ncol)
x <- as.data.frame(x)
return(x)
}
n <- 1e5
col <- 100
data <- get_random_df(n_elements = n, ncol = col)
get_random_df <-
function(n_elements, ncol, min = 0, max = 1, seed = 42) {
seed <- set.seed(seed)
n <- n_elements #number of elements in a vector
x <- runif(n, min = min, max = max) #random vector of real numbers
x <- matrix(x, ncol=ncol)
x <- as.data.frame(x)
return(x)
}
n <- 1e5
col <- 100
data <- get_random_df(n_elements = n, ncol = col)
rbenchmark::benchmark(
rds = saveRDS(data, "../data/data.rds"),
utils = write.csv(data, "../data/data_utils.csv"),
readr = write_csv(data, "../data/data_readr.csv"),
data.table = fwrite(data,"../data/data_dt.csv"),
vroom = vroom_write(data, "../data/data_vroom.csv"),
replications = 1,
columns = c('test', 'elapsed'),
order = 'elapsed'
)
benchmark(
rds = saveRDS(data, "../data/data.rds"),
utils = write.csv(data, "../data/data_utils.csv"),
readr = write_csv(data, "../data/data_readr.csv"),
data.table = fwrite(data,"../data/data_dt.csv"),
vroom = vroom_write(data, "../data/data_vroom.csv"),
replications = 1,
columns = c('test', 'elapsed'),
order = 'elapsed'
)
benchmark(
rds = saveRDS(data, "../data/data.rds"),
utils = write.csv(data, "../data/data_utils.csv"),
readr = write_csv(data, "../data/data_readr.csv"),
data.table = fwrite(data,"../data/data_dt.csv"),
vroom = vroom_write(data, "../data/data_vroom.csv"),
replications = 1,
columns = c('test', 'elapsed'),
order = 'elapsed'
)
benchmark(
rds = readRDS("../data/data.rds"),
utils = read.csv("../data/data_utils.csv"),
readr = read_csv("../data/data_readr.csv"),
data.table = fread("../data/data_dt.csv"),
vroom = vroom("../data/data_vroom.csv"),
replications = 1,
columns = c('test', 'elapsed'),
order = 'elapsed'
)
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #comment out when knitting the notebook
pacman::p_load(
tidyverse, psych, DT, doParallel, data.table, rbenchmark, benchmarkme, microbenchmark, vroom, disk.frame, knitr
)
opts_chunk$set(echo=T, cache=F, prompt=F, tidy=T, comment=NA, message=F, warning=F)
# get major and minor version and paste together
paste0(version$major, ".", version$minor)
# benchmarkme  should already be loaded in your global environment
paste("RAM:", disk.frame::df_ram_size(), "GB") #how much RAM are you working with?
paste("CPUs:", benchmarkme::get_cpu()[3]) #how many logical processors do you have?
write_read_bench <- benchmark_io( size = 5 ) #read and write benchmark
plot(write_read_bench) #plot results
# this example was taken from section 3.2.1 of Efficient R Programming (2021)
n <- 1000
method1 = function(n) {
vec = NULL #or vec = c()
for (i in seq_len(n))
vec = c(vec, i)
vec
}
method2 = function(n) seq_len(n)
seq_len(n)
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #comment out when knitting the notebook
pacman::p_load(
tidyverse, psych, DT, doParallel, data.table, rbenchmark, benchmarkme, microbenchmark, vroom, disk.frame, knitr
)
opts_chunk$set(echo=T, cache=F, prompt=F, tidy=T, comment=NA, message=F, warning=F)
# get major and minor version and paste together
paste0(version$major, ".", version$minor)
# benchmarkme  should already be loaded in your global environment
paste("RAM:", disk.frame::df_ram_size(), "GB") #how much RAM are you working with?
paste("CPUs:", benchmarkme::get_cpu()[3]) #how many logical processors do you have?
write_read_bench <- benchmark_io( size = 5 ) #read and write benchmark
tbl <- tibble(
num = 1:50,
char = rep(c("x","y"), each = 25)
)
rm(list = ls()) #clear the global environment
data(bfi) #get data
glimpse(bfi) #take a look at the data structure using glimpse from the tibble package
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #comment out when knitting the notebook
pacman::p_load(
tidyverse, psych, DT, doParallel, data.table, rbenchmark, benchmarkme, microbenchmark, vroom, disk.frame, knitr
)
opts_chunk$set(echo=T, cache=F, prompt=F, tidy=T, comment=NA, message=F, warning=F)
rm(list = ls()) #clear the global environment
data(bfi) #get data
glimpse(bfi) #take a look at the data structure using glimpse from the tibble package
bfi <- bfi[complete.cases(bfi),] #drop cases with at least 1 missing value
bfi_trim <- bfi %>% select(-gender, -age, -education) #or subset(bfi, select= -c(gender, age, education)) to drop gender, age, edu columns
glimpse(bfi_trim) #check the structure again to compare
mu <- colMeans(bfi_trim) #get variable means
sd <- apply(bfi_trim, 2, sd) #get variable SDs
cor_m <- cor(bfi_trim) #get correlation matrix
cov_m <- sd %*% t(sd) * cor_m #get covariance matrix
set.seed(9201994)
bfi_df <-anMC::mvrnormArma(1e6, mu, cov_m, 0) %>%
t() %>% #transpose
as.data.frame() #get data.frame
names(bfi_df) <- names(bfi_trim)
# let's keep things proportional
gender <- round(table(bfi$gender)/nrow(bfi), digits = 5) #gender proportion
gender #view gender
n <- length(gender)
genders <- as.numeric(names(gender))
gender_vec <- c()
microbenchmark(times = 10, unit = "s",
# growing a vector
gender_vec_grow =
for(i in 1:n) {
gender_vec <- c(gender_vec, rep(genders[i], 1e6 * gender[i]))
},
# vectorized
gender_vec =
rep(genders[1:n], 1e6 * gender[1:n])
)
gender_vec <- rep(genders[1:n], 1e6 * gender[1:n])
bfi_df$gender <- sample(gender_vec) #assigning proportions to gender vector on bfi_df. adding sample randomizes the order of the vector
# let's keep things proportional
age <- round(table(bfi$age)/nrow(bfi), digits = 5)
age #view age proportions
age_vec <- vector()
n <- length(age)
ages <- as.numeric(names(age))
age_vec <- rep(ages[1:n], 1e6 * age[1:n])
bfi_df$age <- sample(age_vec)
# let's keep things proportional
education <- round(table(bfi$education)/nrow(bfi), digits = 5)
education #view education proportions
education_vec <- c()
n <- length(education)
educations <- as.numeric(names(education))
education_vec <- rep(educations[1:n], 1e6 * education[1:n])
bfi_df$education <- sample(education_vec)
# let's keep things proportional
education <- round(table(bfi$education)/nrow(bfi), digits = 5)
education #view education proportions
education_vec <- c()
n <- length(education)
educations <- as.numeric(names(education))
education_vec <- rep(educations[1:n], 1e6 * education[1:n])
bfi_df$education <- sample(education_vec)
bfi_group <- bfi_df[-which(names(bfi_df)=="age")] #or bfi_df %>% select(-age)
benchmark(
psych_describeBy = psych::describeBy(bfi_group[1:25], list(bfi_group$gender, bfi_group$education), mat=T),
rstatix_groupby = bfi_group %>% group_by(gender, education) %>% get_summary_stats(),
replications = 1,
columns = c('test', 'elapsed'),
order = 'elapsed'
)
bfi_tbl <- as_tibble(bfi_df)  #converting to tbl_df & dropping age
bfi_tbl_group <- bfi_tbl %>%  #grab tbl
pivot_longer(               #pivot BFI items
A1:O5,
names_to = "item",        #name gathered column
values_to = "score"       #name values columns
) %>%
select(-age, -education) %>% #drop age, edu columns
group_by(item)              #group by item
glimpse(bfi_tbl_group)
bfi_tbl_group_slice <-
bfi_tbl_group %>%
ungroup(item) %>%
slice(1:1000) %>%
group_by(item)
bfi_tbl_group_slice
bfi_tbl_long
bfi_tbl_long <-  bfi_tbl_group %>% slice(1:1e5)  #2.5 mil (2500k)
bfi_tbl_long
bfi
qref = c(names(bfi))
bfi %>% select(starts_with("A"))
bfi %>% select(starts_with("A"), -age)
rm(list = ls()) #clear the global environment
gimplse(bfi)
glimpse(bfi)
bfi_ls <- list(
agree <- bfi %>% select(starts_with("A"), -age)
)
bfi_ls <- list(
agree = bfi %>% select(starts_with("A"), -age)
)
View(bfi_ls)
bfi_ls <- list(
agree = bfi %>% select(starts_with("A"), -age),
conscientious = bfi %>% select(starts_with("C")),
extraversion = bfi %>% select(starts_with("E"), -education),
neuroticism = bfi %>% select(starts_with("N")),
openness = bfi %>% select(starts_with("O"))
)
bfi_ls
lapply(bfi_ls, function(x)
colnames(x) <- paste0("item", 1:5)
)
bfi_ls <- lapply(bfi_ls, function(x)
colnames(x) <- paste0("item", 1:5)
)
View(bfi_ls)
bfi_ls[["agree"]]
bfi_ls <- list(
agree = bfi %>% select(starts_with("A"), -age),
conscientious = bfi %>% select(starts_with("C")),
extraversion = bfi %>% select(starts_with("E"), -education),
neuroticism = bfi %>% select(starts_with("N")),
openness = bfi %>% select(starts_with("O"))
)
bfi_ls <- list(
agree = bfi %>% select(starts_with("A"), -age),
conscientious = bfi %>% select(starts_with("C")),
extraversion = bfi %>% select(starts_with("E"), -education),
neuroticism = bfi %>% select(starts_with("N")),
openness = bfi %>% select(starts_with("O"))
)
bfi_ls <- lapply(bfi_ls, function(x)
names(x) <- paste0("item", 1:5)
)
bfi_ls <- list(
agree = bfi %>% select(starts_with("A"), -age),
conscientious = bfi %>% select(starts_with("C")),
extraversion = bfi %>% select(starts_with("E"), -education),
neuroticism = bfi %>% select(starts_with("N")),
openness = bfi %>% select(starts_with("O"))
)
for(i in seq_along(bfi_ls)) {
colnames(bfi_ls[[i]]) <- paste0("item", 1:5)
}
paste("trait =~", paste("item", 1:5, sep = "+"))
c("trait =~", paste("item", 1:5, sep = "+"))
paste("trait =~", paste("item", 1:5, sep = "+"))
character("trait =~", paste("item", 1:5, sep = "+"))
paste0("trait =~", paste("item", 1:5, sep = "+"))
paste("trait =~", "item", 1:5, "+")
paste("item", 1:5, "+")
c(paste("item", 1:5, "+"))
valCFA = foreach (i = bfi_ls, .multicombine = T, .errorhandling = "pass") %dopar% {
cfa(model =  "trait =~ item1 + item2 + item3 + item4 + item5",
data = bfi_ls[i]
)
}
registerDoParallel(detectCores()-1)
valCFA = foreach (i = bfi_ls, .multicombine = T, .errorhandling = "pass") %dopar% {
cfa(model =  "trait =~ item1 + item2 + item3 + item4 + item5",
data = bfi_ls[i]
)
}
View(valCFA)
valCFA[[1]]
valCFA = foreach (i = bfi_ls, .multicombine = T, .errorhandling = "pass") %dopar% {
cfa(model =  "trait =~ item1 + item2 + item3 + item4 + item5",
data = bfi_ls[[i]]
)
}
valCFA = foreach (i = bfi_ls, .multicombine = T, .errorhandling = "pass") %dopar% {
cfa(model =  "trait =~ item1 + item2 + item3 + item4 + item5",
data = bfi_ls
)
}
registerDoParallel(detectCores()-1)
valCFA = foreach (i = 1:5, .multicombine = T, .errorhandling = "pass") %dopar% {
cfa(model =  "trait =~ item1 + item2 + item3 + item4 + item5",
data = bfi_ls[[i]]
)
}
View(valCFA)
registerDoParallel(detectCores()-1)
cfa = foreach (i = 1:5, .multicombine = T, .errorhandling = "pass") %dopar% {
psych::cfa(model =  "trait =~ item1 + item2 + item3 + item4 + item5",
data = bfi_ls[[i]]
)
}
?cfa
??cfa
registerDoParallel(detectCores()-1)
cfa = foreach (i = 1:5, .multicombine = T, .errorhandling = "pass") %dopar% {
lavaan::cfa(model =  "trait =~ item1 + item2 + item3 + item4 + item5",
data = bfi_ls[[i]]
)
}
install.packages(lavaan)
pacman::p_load(lavaan)
registerDoParallel(detectCores()-1)
cfa = foreach (i = 1:5, .multicombine = T, .errorhandling = "pass") %dopar% {
lavaan::cfa(model =  "trait =~ item1 + item2 + item3 + item4 + item5",
data = bfi_ls[[i]]
)
}
View(valCFA)
View(cfa)
cfa[[1]]
models = foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
nobs <- inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq.scaled","df.scaled","pvalue.scaled","cfi.scaled","rmsea.scaled","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(qref[i], nobs, fm, maxLoading, minLoading))
}
pacman::p_load(lavaan)
registerDoParallel(detectCores()-1)
cfa <- foreach (i = 1:5, .multicombine = T, .errorhandling = "pass") %dopar% {
lavaan::cfa(model =  "trait =~ item1 + item2 + item3 + item4 + item5",
data = bfi_ls[[i]]
)
}
models <-  foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
nobs <- inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq.scaled","df.scaled","pvalue.scaled","cfi.scaled","rmsea.scaled","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(qref[i], nobs, fm, maxLoading, minLoading))
}
models_output <-  rbindlist(models, use.names = F)
models_output <-  data.table::rbindlist(models, use.names = F)
data.table::rbindlist(models, use.names = F)
View(models)
models = foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
nobs <- inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq.scaled","df.scaled","pvalue.scaled","cfi.scaled","rmsea.scaled","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(qref[i], nobs, fm, maxLoading, minLoading))
}
pacman::p_load(lavaan)
models = foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
nobs <- inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq.scaled","df.scaled","pvalue.scaled","cfi.scaled","rmsea.scaled","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(qref[i], nobs, fm, maxLoading, minLoading))
}
View(models)
models[[1]]
models = foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
nobs <- lavaan::inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq.scaled","df.scaled","pvalue.scaled","cfi.scaled","rmsea.scaled","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(qref[i], nobs, fm, maxLoading, minLoading))
}
models = foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
pacman::p_load(lavaan)
nobs <- inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq.scaled","df.scaled","pvalue.scaled","cfi.scaled","rmsea.scaled","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(qref[i], nobs, fm, maxLoading, minLoading))
}
models <- foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
pacman::p_load(lavaan)
nobs <- inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq.scaled","df.scaled","pvalue.scaled","cfi.scaled","rmsea.scaled","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(qref[i], nobs, fm, maxLoading, minLoading))
}
View(models)
models[[1]]
models <- foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
pacman::p_load(lavaan)
nobs <- inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq","df","pvalue","cfi","rmsea","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(qref[i], nobs, fm, maxLoading, minLoading))
}
models <- foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
pacman::p_load(lavaan)
nobs <- inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq","df","pvalue","cfi","rmsea","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(bfi_ls[i], nobs, fm, maxLoading, minLoading))
}
View(models)
models[[1]]
models_output <-  data.table::rbindlist(models, use.names = F)
colnames(models_output) = c('qref', 'N', "chisq.scaled","df.scaled","pvalue.scaled","cfi.scaled","rmsea.scaled","srmr",'max_loading','min_loading')
models_output
data.table::rbindlist(models, use.names = F)
data.table::rbindlist(models)
models <- foreach(i = 1:length(cfa), .multicombine = T, .errorhandling = "pass") %dopar% {
pacman::p_load(lavaan)
nobs <- inspect(cfa[[i]], what ='nobs')
fm <- fitMeasures(cfa[[i]], c("chisq","df","pvalue","cfi","rmsea","srmr"))
maxLoading <- max(lavInspect(cfa[[i]], what='est')$lambda)
minLoading <- min(lavInspect(cfa[[i]], what='est')$lambda)
as.list(c(names(bfi_ls[i]), nobs, fm, maxLoading, minLoading))
}
models_output <-  data.table::rbindlist(models)
colnames(models_output) <-  c('trait','N',"chisq","df","pvalue","cfi","rmsea","srmr",'max_loading','min_loading')
models_output
registerDoSEQ()
models_output %>% mutate(across(where(is.numeric), round))
models_output %>% mutate(across(N:min_loading, as.numeric))
models_output %>% mutate(across(N:min_loading, as.numeric)) %>% round()
models_output %>%
mutate(across(N:min_loading, as.numeric)) %>%
mutate(across(where(is.numeric), round))
models_output %>%
mutate(across(N:min_loading, as.numeric)) %>%
mutate(across(where(is.numeric), round(2)))
models_output %>%
mutate(across(N:min_loading, as.numeric)) %>%
mutate(across(where(is.numeric), ~round(2)))
models_output %>%
mutate(across(N:min_loading, as.numeric)) %>%
mutate(across(where(is.numeric), ~round(digits = 3)))
models_output %>%
mutate(across(N:min_loading, as.numeric)) %>%
mutate(across(where(is.numeric), ~round(., digits = 3)))
